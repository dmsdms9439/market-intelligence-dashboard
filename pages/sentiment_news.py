%%writefile module/pr1cr.py

import streamlit as st
import yfinance as yf
import requests as req
import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from konlpy.tag import Okt
from collections import Counter
import re
import numpy as np
from PIL import Image

# 1. ë„¤ì´ë²„ API ì„¤ì •
NAVER_CLIENT_ID = '5oVXMqrseId0LObau9b9'
NAVER_CLIENT_SECRET = 'JTk7ZQRTpj'

@st.cache_data(ttl=3600)
def get_vix_data():
    """ê³µí¬ì§€ìˆ˜(VIX) ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    vix = yf.download("^VIX", period="2d")
    if not vix.empty and len(vix) >= 2:
        current_vix = vix['Close'].iloc[-1]
        prev_vix = vix['Close'].iloc[-2]
        delta = current_vix - prev_vix
        return float(current_vix), float(delta)
    return None, None

def clean_html(text):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²°ê³¼ì—ì„œ HTML íƒœê·¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
    clean = re.sub('<.*?>', '', text) # íƒœê·¸ ì œê±°
    clean = re.sub('&#39;', "'", clean)
    clean = re.sub('&quot;', '"', clean)
    clean = re.sub('&amp;', '&', clean)
    return clean

@st.cache_data(ttl=3600)
def get_naver_news(query='ê±°ì‹œê²½ì œ', display=30):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ"""
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display={display}&sort=sim"
    N_A = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    res = req.get(url, headers=N_A)
    
    if res.status_code == 200:
        items = res.json().get('items', [])
        for item in items:
            item['title'] = clean_html(item['title'])
            item['description'] = clean_html(item['description'])
        return items
    else:
        st.error(f"ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨: {res.status_code}")
        return []

def create_wordcloud(news_items):
    """ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ê¸°ë°˜ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    okt = Okt()
    all_titles = " ".join([item['title'] for item in news_items])
    
    # ëª…ì‚¬ ì¶”ì¶œ ë° ë¶ˆìš©ì–´ ì œê±°
    nouns = okt.nouns(all_titles)
    stopwords = ['ë‰´ìŠ¤', 'ê²½ì œ', 'ì‹œì¥', 'ì˜¤ëŠ˜', 'ë‚ ', 'í¬í† ', 'ê¸°ì', 'ì¦ì‹œ', 'ë¶„ì„']
    words = [n for n in nouns if len(n) > 1 and n not in stopwords]
    
    count = Counter(words)
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (WindowsëŠ” malgun.ttf, Macì€ AppleGothic.ttf)
    # í°íŠ¸ ê²½ë¡œê°€ í‹€ë¦¬ë©´ ì˜¤ë¥˜ê°€ ë‚˜ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”!
    wc = WordCloud(
        font_path="malgun.ttf", 
        background_color="white",
        width=800, height=400
    ).generate_from_frequencies(count)
    
    return wc

def wcChart(new_items, back_mask, max_words, emp):
    # ë°°ê²½ ì´ë¯¸ì§€ ì„ íƒ
    if back_mask =='íƒ€ì›':
        img = Image.open('data/background_1.png')
    elif back_mask =='ë§í’ì„ ':
        img = Image.open('data/background_2.png')
    elif back_mask =='í•˜íŠ¸':
        img = Image.open('data/background_3.png')
    else :
        img = Image.open('data/background_0.png')

    my_mask = np.array(img)
    
    wc = WordCloud(
        font_path=r'C:\Windows\Fonts\Gulim.ttc',
        background_color='white',                  # ë°°ê²½ìƒ‰ ì§€ì •
        max_words=max_words,                              # í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ì¸ max_word ì…ë ¥
        random_state=99,                           # ì¶œë ¥ìœ„ì¹˜ ê³ ì • ëœë¤ ì‹œë“œê°’
        stopwords=['ìˆë‹¤', 'ë°', 'ìˆ˜', 'ì´', 'ë‹¤', 'the', 'a', 'of', 'to', 'in', 'and'], # ì œì™¸í•˜ê³  ì‹¶ì€ ë‹¨ì–´ ì„¤ì •(ë¶ˆìš©ì–´ ì„¤ì •)
        mask=my_mask,
        contour_color='black',
        contour_width=3)
    
    wc.generate(new_items)
    fig = plt.subplots(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    st.pyplot(fig)

# --- UI ë Œë”ë§ ---
st.header("ğŸ” ì‹œì¥ ì‹¬ë¦¬ ë° ë‰´ìŠ¤ ë¶„ì„")

# â‘  VIX ì§€ìˆ˜
vix_val, vix_delta = get_vix_data()
if vix_val is not None:
    st.subheader("ğŸ“Š ì˜¤ëŠ˜ì˜ ê³µí¬ ì§€ìˆ˜ (VIX)")
    col1, col2 = st.columns([1, 2])
    with col1:
        st.metric(label="VIX ì§€ìˆ˜", value=f"{vix_val:.2f}", delta=f"{vix_delta:.2f}", delta_color="inverse")
    with col2:
        if vix_val < 20:
            st.success("â˜€ï¸ ì‹œì¥ì´ í‰ì˜¨í•©ë‹ˆë‹¤. íˆ¬ì ì‹¬ë¦¬ê°€ ê¸ì •ì ì…ë‹ˆë‹¤.")
        elif vix_val < 30:
            st.warning("â˜ï¸ ë³€ë™ì„±ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.error("â›ˆï¸ ì‹œì¥ì— ê³µí¬ê°€ ê°€ë“í•©ë‹ˆë‹¤! ì•ˆì „ ìì‚° í™•ë³´ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

st.divider()

# â‘¡ ì›Œë“œí´ë¼ìš°ë“œ
st.subheader("â˜ï¸ ë‰´ìŠ¤ í‚¤ì›Œë“œ íŠ¸ë Œë“œ")
news_items = get_naver_news()

if news_items:
    try:
        wcChart(corpus, back_mask, max_words, emp)
    except Exception as e:
        st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ë ¤ë©´ í•œê¸€ í°íŠ¸ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

st.divider()

# â‘¢ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¦¬ìŠ¤íŠ¸
st.subheader("ğŸ“° ì‹¤ì‹œê°„ ì£¼ìš” ë‰´ìŠ¤")
for item in news_items[:8]: # 8ê°œ ì¶œë ¥
    with st.expander(f"ğŸ“Œ {item['title']}"):
        st.write(item['description'])
        st.markdown(f"[ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({item['link']})")