import streamlit as st
import yfinance as yf
import requests as req
import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
import numpy as np
from PIL import Image
import json
import html

# 1. ë„¤ì´ë²„ API ì„¤ì •
NAVER_CLIENT_ID = "8xWG51_vAzI7wHiEjYB4"
NAVER_CLIENT_SECRET = "xIiND03IGe"


@st.cache_data(ttl=3600)
def get_vix_data():
    """ê³µí¬ì§€ìˆ˜(VIX) ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        # period='1mo'ë¡œ ë³€ê²½í•˜ì—¬ ìµœê·¼ í•œ ë‹¬ ì¶”ì´ë¥¼ ê°€ì ¸ì˜¤ê¸°.
        vix = yf.download("^VIX", period="1mo", progress=False)

        if not vix.empty and len(vix) >= 2:
            current_vix = vix["Close"].iloc[-1]
            prev_vix = vix["Close"].iloc[-2]
            delta = current_vix - prev_vix

            # í˜„ì¬ê°’, ë“±ë½í­, ê·¸ë¦¬ê³  ê·¸ë˜í”„ìš© íˆìŠ¤í† ë¦¬(ì „ì²´ ë°ì´í„°) ë°˜í™˜
            return float(current_vix), float(delta), vix["Close"]
    except Exception as e:
        print(f"VIX Fetch Error: {e}")
        pass
    return None, None, None


def clean_html(text):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²°ê³¼ì—ì„œ HTML íƒœê·¸ ì œê±° ë° íŠ¹ìˆ˜ë¬¸ì ì™„ë²½ ë³µì›
    """
    clean = re.sub(r"<[^>]*>", "", text)  # 1. ì •ê·œì‹ì„ ì´ìš©í•œ HTML íƒœê·¸ ì œê±°
    clean = html.unescape(clean)  # 2. HTML ì—”í‹°í‹° ë³µì› (&quot; -> ", &amp; -> & ë“±)
    clean = clean.strip()  # 3. ì¶”ê°€ì ì¸ ê³µë°± ì •ëˆ (í•„ìš” ì‹œ)
    return clean


@st.cache_data(ttl=3600)
def get_naver_news(keyword="íŠ¹ì§•ì£¼", display=100):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ"""
    url = f"https://openapi.naver.com/v1/search/news.json?query={keyword}&display={display}&sort=sim"
    N_A = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    res = req.get(url, headers=N_A)
    my_json = json.loads(res.text)

    # --- ì›ë³¸ ì½”ë“œì˜ í•„í„°ë§ ë° ì¶œë ¥ ë£¨í”„ ---
    filtered_list = []  # í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    cnt = 1

    for i in my_json.get("items", []):
        # ë„¤ì´ë²„ ë‰´ìŠ¤ í”Œë«í¼ ë§í¬(n.news.naver)ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
        if "n.news.naver" in i.get("link", ""):
            # ì½˜ì†” ì¶œë ¥
            print("Count :", str(cnt))
            print("Title :", i.get("title"))
            print("Link :", i.get("link"))
            print("Description :", i.get("description"))
            print()

            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë‚˜ì¤‘ì— ë°ì´í„°ë¡œ ì“¸ ìˆ˜ ìˆê²Œ)
            filtered_list.append(i)
            cnt += 1

    return filtered_list  # í•„í„°ë§ëœ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜


def get_unique_companies(news_items):
    """
    [í•µì‹¬ ê¸°ëŠ¥] ë‰´ìŠ¤ ì œëª©ì—ì„œ ì²« ë²ˆì§¸ ë‹¨ì–´(ê¸°ì—…ëª…)ë¥¼ ì¶”ì¶œí•´ ì¤‘ë³µ ì œê±°
    """
    unique_list = []
    seen_companies = set()

    for item in news_items:
        # 1. íƒœê·¸ ë° HTML ì œê±°
        title = clean_html(item["title"])

        # 2. [íŠ¹ì§•ì£¼] ê°™ì€ ëŒ€ê´„í˜¸ ì‚­ì œ
        title_no_tag = re.sub(r"\[.*?\]", "", title)
        title_no_tag = re.sub(r"\(.*?\)", "", title_no_tag)

        # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ê³µë°± ì •ë¦¬
        clean_t = re.sub(r"[^\w\s]", " ", title_no_tag).strip()

        if not clean_t:
            continue

        # 4. ì²« ë‹¨ì–´ ì¶”ì¶œ (ì´ê²Œ ë³´í†µ ê¸°ì—…ëª…)
        words = clean_t.split()
        if not words:
            continue

        company_name = words[0]  # ì˜ˆ: 'ì´ë§ˆíŠ¸', 'ë„¥ì„¼íƒ€ì´ì–´'

        # 5. ì¤‘ë³µ ì•„ë‹ˆë©´ ì¶”ê°€
        if company_name not in seen_companies:
            unique_list.append(item)
            seen_companies.add(company_name)

    return unique_list


def render_sentiment_news():

    def wcChart(news_items):
        """
        ë‰´ìŠ¤ ì œëª©ì˜ íŒ¨í„´ì„ ë¶„ì„í•´ 'ì¢…ëª©ëª…'ë§Œ ì¶”ì¶œí•˜ì—¬ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        """
        try:
            stock_names = []

            # ì›Œë“œí´ë¼ìš°ë“œì—ì„œ ëº„ ë‹¨ì–´ë“¤ (í˜¹ì‹œ ì²« ë‹¨ì–´ë¡œ ë‚˜ì˜¤ë”ë¼ë„ ë¬´ì‹œ)
            STOPWORDS = [
                "íŠ¹ì§•ì£¼",
                "ì˜¤ì „",
                "ì˜¤í›„",
                "ì¥ì¤‘",
                "ë§ˆê°",
                "ì†ë³´",
                "ì¢…í•©",
                "ê¸‰ë“±",
                "ê¸‰ë½",
                "ìƒìŠ¹",
                "í•˜ë½",
                "ê°•ì„¸",
                "ì•½ì„¸",
                "ì½”ìŠ¤í”¼",
                "ì½”ìŠ¤ë‹¥",
                "ì¦ì‹œ",
                "ë‹¨ë…",
                "ì£¼ì‹",
                "ETíŠ¹ì§•ì£¼",
                "í¬í† ",
                "íˆ¬ì",
                "ê³µì‹œ",
                "ë‰´ìŠ¤",
                "íˆ¬ë°ì´",
            ]

            for item in news_items:
                # 1. HTML íƒœê·¸ ë° ê¸°ì‚¬ ë§ë¨¸ë¦¬([...]) ì œê±°
                title = clean_html(item["title"])
                title = re.sub(r"\[.*?\]", "", title)  # [íŠ¹ì§•ì£¼] ì œê±°
                title = re.sub(r"\(.*?\)", "", title)  # (ì¢…í•©) ì œê±°

                # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì‰¼í‘œ, ë”°ì˜´í‘œ ë“±ì„ ê³µë°±ìœ¼ë¡œ)
                # ì˜ˆ: "ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤" -> "ì‚¼ì„±ì „ì  SKí•˜ì´ë‹‰ìŠ¤"
                title = re.sub(r"[^\w\s]", " ", title).strip()

                if not title:
                    continue

                # 3. ë‹¨ì–´ ë¶„ë¦¬
                words = title.split()
                if not words:
                    continue

                # 4. [í•µì‹¬] ë§¨ ì•ì˜ ë‹¨ì–´ 1~2ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
                # ë³´í†µ ì²« ë²ˆì§¸ ë‹¨ì–´ê°€ ì¢…ëª©ëª…ì´ì§€ë§Œ, "ì‚¼ì„±ì „ì SKí•˜ì´ë‹‰ìŠ¤"ì²˜ëŸ¼ ë‘ ê°œê°€ ì˜¬ ìˆ˜ë„ ìˆìŒ
                # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ 'ì²« ë²ˆì§¸ ë‹¨ì–´'ë§Œ ê°€ì ¸ì™€ì„œ ì¢…ëª©ëª…ìœ¼ë¡œ ê°„ì£¼
                candidate = words[0]

                # 5. ê¸€ì ìˆ˜ 2ê°œ ì´ìƒì´ê³ , ê¸ˆì§€ì–´(STOPWORDS)ì— ì—†ìœ¼ë©´ ì¢…ëª©ìœ¼ë¡œ ì¸ì •
                if len(candidate) >= 2 and candidate not in STOPWORDS:
                    stock_names.append(candidate)

            # 6. ë¹ˆë„ìˆ˜ ê³„ì‚° (Counter í™œìš©)
            # í…ìŠ¤íŠ¸ ë­‰ì¹˜ê°€ ì•„ë‹ˆë¼ {'ì‚¼ì„±ì „ì': 5, 'ì¹´ì¹´ì˜¤': 3} í˜•íƒœì˜ ë°ì´í„° ìƒì„±
            counts = Counter(stock_names)

            # 7. ìƒìœ„ 30ê°œ ì¢…ëª©ë§Œ ì¶”ì¶œ
            top_stocks = dict(counts.most_common(30))

            # 8. ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (generate_from_frequencies ì‚¬ìš©)
            try:
                img = Image.open("data/background_2.png")
                my_mask = np.array(img)
            except:
                my_mask = None

            wc = WordCloud(
                font_path=r"C:\Windows\Fonts\Gulim.ttc",
                background_color="white",
                max_words=30,  # ì¢…ëª© 30ê°œë§Œ ê¹”ë”í•˜ê²Œ
                mask=my_mask,
                colormap="Dark2",  # ê¸€ìê°€ ì§„í•˜ê²Œ ì˜ ë³´ì´ëŠ” ìƒ‰ìƒ í…Œë§ˆ
                contour_color="black",
                contour_width=2,
                normalize_plurals=False,  # ë‹¨ì–´ ë³€í˜• ë°©ì§€
            ).generate_from_frequencies(
                top_stocks
            )  # [ì¤‘ìš”] ë¹ˆë„ìˆ˜ ë°ì´í„°ë¡œ ìƒì„±

            # ê·¸ë˜í”„ ì¶œë ¥
            fig = plt.figure(figsize=(10, 5))
            plt.imshow(wc, interpolation="bilinear")
            plt.axis("off")
            st.pyplot(fig)

            # (ì„ íƒì‚¬í•­) ì–´ë–¤ ì¢…ëª©ë“¤ì´ ë“¤ì–´ê°”ëŠ”ì§€ í„°ë¯¸ë„ì—ì„œ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì£¼ì„ í•´ì œ
            # print(top_stocks)

        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ì—ëŸ¬: {e}")

    # --- UI ë Œë”ë§ ---
    st.header("ğŸ” ì‹œì¥ ì‹¬ë¦¬ ë° ë‰´ìŠ¤ ë¶„ì„")

    # â‘  VIX ì§€ìˆ˜
    vix_val, vix_delta, vix_history = get_vix_data()

    if vix_val is not None:
        st.subheader("ğŸ“Š ì˜¤ëŠ˜ì˜ ê³µí¬ ì§€ìˆ˜ (VIX)")

        # 1:2 ë¹„ìœ¨ë¡œ ì»¬ëŸ¼ ë¶„í•  (ì™¼ìª½: ìˆ˜ì¹˜, ì˜¤ë¥¸ìª½: ê·¸ë˜í”„)
        col1, col2 = st.columns([1, 2])

        with col1:
            st.metric(
                label="VIX ì§€ìˆ˜",
                value=f"{vix_val:.2f}",
                delta=f"{vix_delta:.2f}",
                delta_color="inverse",
            )
            # ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ
            if vix_val < 20:
                st.success("â˜€ï¸ í‰ì˜¨ (Greed)")
            elif vix_val < 30:
                st.warning("â˜ï¸ ì£¼ì˜ (Fear)")
            else:
                st.error("â›ˆï¸ ê³µí¬ (Extreme Fear)")

        with col2:
            # VIX ì¶”ì„¸ ê·¸ë˜í”„ (ìµœê·¼ 1ë‹¬)
            st.caption("ğŸ“‰ ìµœê·¼ 1ê°œì›” VIX ì¶”ì´")
            st.line_chart(vix_history, height=150, color="#FF0000")  # ë¶‰ì€ìƒ‰ ë¼ì¸ ì°¨íŠ¸
    st.divider()

    # â‘¡ ì›Œë“œí´ë¼ìš°ë“œ
    st.subheader("â˜ï¸ ë‰´ìŠ¤ í‚¤ì›Œë“œ íŠ¸ë Œë“œ")  # ì£¼ì˜ê¹Šê²Œ ë´ì•¼í•  íšŒì‚¬ë“¤ë¡œ êµì²´?

    news_items = get_naver_news()

    if news_items:
        try:
            data_amount = st.slider("ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜", 1, 50, 10)
            wcChart(news_items)
        except Exception as e:
            st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}")

    st.divider()

    # â‘¢ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¦¬ìŠ¤íŠ¸
    st.subheader("ğŸ“° ì‹¤ì‹œê°„ ì£¼ìš” ë‰´ìŠ¤")

    if news_items:
        # [ì—¬ê¸°ì„œ í•¨ìˆ˜ í˜¸ì¶œ] ê¸°ì—…ë³„ë¡œ í•˜ë‚˜ë§Œ ë‚¨ê¸´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ìŒ
        unique_news = get_unique_companies(news_items)

        # ìƒìœ„ 8ê°œ ê¸°ì—… ì¶œë ¥
        for item in unique_news[:15]:
            title = clean_html(item["title"])
            desc = clean_html(item["description"])

            with st.expander(f"ğŸ“Œ {title}"):
                st.write(desc)
                st.markdown(f"[ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({item['link']})")
    else:
        st.write("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
