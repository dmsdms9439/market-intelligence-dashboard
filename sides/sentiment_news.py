import streamlit as st
import yfinance as yf
import requests as req
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import json
import html
import re
from wordcloud import WordCloud
from PIL import Image
from collections import Counter


# 1. ë„¤ì´ë²„ API ì„¤ì •
NAVER_CLIENT_ID = "5oVXMqrseId0LObau9b9"
NAVER_CLIENT_SECRET = "JTk7ZQRTpj"


# ================ í•¨ìˆ˜ ì„ ì–¸ ==================
@st.cache_data(ttl=3600)  # 1ì‹œê°„ë™ì•ˆ ìºì‹±
def get_vix_data():
    # ê³µí¬ì§€ìˆ˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    try:
        vix = yf.download("^VIX", period="6mo")
        if not vix.empty and len(vix) >= 2:
            # ê°€ì ¸ì˜¨ ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆë¨
            # ì „ë‚ ê³¼ ì˜¤ëŠ˜ì˜ ë¹„êµë¥¼ í•´ì•¼í•˜ë¯€ë¡œ ìµœì†Œ 2ê°œ
            current_vix = vix["Close"].iloc[-1]  # ê°€ì¥ ìµœê·¼ ì¢…ê°€ ë°ì´í„°
            prev_vix = vix["Close"].iloc[-2]  # ê·¸ ì „ë‚  ì¢…ê°€ ë°ì´í„°
            delta = current_vix - prev_vix  # ë³€ë™í­

            # í˜„ì¬ê°’, ë³€ë™í­, ì „ì²´ë°ì´í„°
            return float(current_vix), float(delta), vix["Close"]
    except Exception as e:
        print(f"VIX ERROR : {e}")


def clean_html(text):
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²°ê³¼ì—ì„œ HTML íƒœê·¸ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ë³µì›
    clean = re.sub(r"<[^>]*>", "", text)  # ì •ê·œì‹ìœ¼ë¡œ íƒœê·¸ ì œê±°
    clean = html.unescape(clean)  # íŠ¹ìˆ˜ë¬¸ì ì•”í˜¸ë¡œ ëœ ê²ƒ ë³µì›
    clean = clean.strip()  # ê³µë°± ì œê±°
    return clean


@st.cache_data(ttl=3600)
def get_naver_news(keyword="íŠ¹ì§•ì£¼", display=100):
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ
    url = f"https://openapi.naver.com/v1/search/news.json?query={keyword}&display={display}&sort=sim"
    N_A = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    res = req.get(url, headers=N_A)
    my_json = json.loads(res.text)  # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

    filtered_list = []  # ì •ì œëœ ë‰´ìŠ¤ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    cnt = 1

    for i in my_json.get("items", []):
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
        if "n.news.naver" in i.get("link", ""):
            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            filtered_list.append(i)
            cnt += 1
    return filtered_list


def get_unique_companies(news_items):
    # ë‰´ìŠ¤ ì œëª©ì—ì„œ ì²«ë²ˆì§¸ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•´ ì¤‘ë³µ ì œê±°
    unique_list = []
    seen_companies = set()  # ì¤‘ë³µëœ ê¸°ì—…ì„ ê¸°ì–µí•´ë‘ëŠ” ì§‘í•©

    for item in news_items:
        # clen í•¨ìˆ˜ë¡œ íƒœê·¸, html ì œê±°
        clean_title = clean_html(item["title"])
        clean_desc = clean_html(item["description"])

        # itemì— ì •ì œëœ ë‚´ìš©ìœ¼ë¡œ êµì²´
        item["title"] = clean_title
        item["description"] = clean_desc

        # ê¸°ì—…ëª…ì´ ì•„ë‹ˆë¼ ê¸°ì‚¬ ë§¨ ì• [ë‹¨ë…], [íŠ¹ì§•ì£¼]ë“¤ì´ ë‚˜ì™€ ëŒ€ê´„í˜¸ ë©ì–´ë¦¬ ì§€ìš°ê¸°
        title_for_extract = re.sub(r"\[.*?\]", "", clean_title)
        title_for_extract = re.sub(r"\(.*?\)", "", title_for_extract)
        clean_t = re.sub(r"[^\w\s]", " ", title_for_extract).strip()

        if not clean_t:
            continue  # ì œëª©ì„ ë‹¤ ì§€ì› ì„ ë•Œ ì•„ë¬´ê²ƒë„ ì•ˆë‚¨ì•˜ë‹¤ë©´ ë‹¤ìŒ ë‰´ìŠ¤ë¡œ ë„˜ì–´ê°€ê¸°

        words = clean_t.split()  # ë„ì–´ì“°ê¸° ê¸°ì¤€ìœ¼ë¡œ í† ë§‰ë‚´ê¸°
        if not words:
            continue

        company_name = words[0]  # ë§¨ ì•ì— ìˆëŠ” ë‹¨ì–´ë¥¼ ê¸°ì—… ì´ë¦„ìœ¼ë¡œ ê°„ì£¼

        # ì¤‘ë³µì¸ ê¸°ì—…ëª… ì§‘í•©ì— ë„£ê¸°
        if company_name not in seen_companies:
            unique_list.append(item)
            seen_companies.add(company_name)

    return unique_list


def render_sentiment_news():

    def wcChart(news_items):
        # ì¢…ëª©ëª…ë§Œ ì¶”ì¶œí•´ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        try:
            stock_names = []

            # ë¶ˆìš©ì–´ ì„¤ì •
            STOPWORDS = [
                "íŠ¹ì§•ì£¼",
                "ì˜¤ì „",
                "ì˜¤í›„",
                "ì¥ì¤‘",
                "ë§ˆê°",
                "ì†ë³´",
                "ì¢…í•©",
                "ê¸‰ë“±",
                "ê¸‰ë½",
                "ìƒìŠ¹",
                "í•˜ë½",
                "ê°•ì„¸",
                "ì•½ì„¸",
                "ì½”ìŠ¤í”¼",
                "ì½”ìŠ¤ë‹¥",
                "ì¦ì‹œ",
                "ë‹¨ë…",
                "ì£¼ì‹",
                "ETíŠ¹ì§•ì£¼",
                "í¬í† ",
                "íˆ¬ì",
                "ê³µì‹œ",
                "ë‰´ìŠ¤",
                "íˆ¬ë°ì´",
            ]
            for item in news_items:
                # 1. HTML íƒœê·¸ ë° ê¸°ì‚¬
                title = clean_html(item["title"])
                title = re.sub(r"\[.*?\]", "", title)  # [íŠ¹ì§•ì£¼] ì œê±°
                title = re.sub(r"\(.*?\)", "", title)  # (ì¢…í•©) ì œê±°
                # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±°
                title = re.sub(r"[^\w\s]", " ", title).strip()
                if not title:
                    continue
                # 3. ë‹¨ì–´ ë¶„ë¦¬
                words = title.split()
                if not words:
                    continue

                # 4. ë§¨ ì•ì˜ ë‹¨ì–´ 1ê°œë§Œ ê°€ì ¸ì™€ì„œ ì¢…ëª©ëª…ìœ¼ë¡œ ê°„ì£¼
                candidate = words[0]

                # 5. ê¸€ì ìˆ˜ 2ê°œ ì´ìƒì´ê³ , ê¸ˆì§€ì–´(STOPWORDS)ì— ì—†ìœ¼ë©´ ì¢…ëª©ìœ¼ë¡œ ì¸ì •
                if len(candidate) >= 2 and candidate not in STOPWORDS:
                    stock_names.append(candidate)

            # 6. ë¹ˆë„ìˆ˜ ê³„ì‚° (Counter í™œìš©)
            # í…ìŠ¤íŠ¸ ë­‰ì¹˜ê°€ ì•„ë‹ˆë¼ {'ì‚¼ì„±ì „ì': 5, 'ì¹´ì¹´ì˜¤': 3} í˜•íƒœì˜ ë°ì´í„° ìƒì„±
            counts = Counter(stock_names)

            # 7. ìƒìœ„ 30ê°œ ì¢…ëª©ë§Œ ì¶”ì¶œ
            top_stocks = dict(counts.most_common(30))

            # 8. ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            try:
                img = Image.open("data/background_2.png")
                my_mask = np.array(img)
            except:
                my_mask = None

            wc = WordCloud(
                font_path=r"C:\Windows\Fonts\Gulim.ttc",
                background_color="white",
                max_words=30,  # ì¢…ëª© 30ê°œë§Œ
                mask=my_mask,
                colormap="Dark2",
                contour_color="black",
                contour_width=2,
                normalize_plurals=False,  # ë‹¨ì–´ ë³€í˜• ë°©ì§€
            )

            wc.generate_from_frequencies(top_stocks)  # ë¹ˆë„ìˆ˜ ë°ì´í„°ë¡œ ìƒì„±
            # ê·¸ë˜í”„ ì¶œë ¥
            fig = plt.figure(figsize=(10, 5))
            plt.imshow(wc, interpolation="bilinear")
            plt.axis("off")
            st.pyplot(fig)

        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ì—ëŸ¬: {e}")

    # --- UI ë Œë”ë§ ---
    st.header("ğŸ” ì‹œì¥ ì‹¬ë¦¬ ë° ë‰´ìŠ¤ ë¶„ì„")

    # â‘  VIX ì§€ìˆ˜
    vix_val, vix_delta, vix_history = get_vix_data()

    if vix_val is not None:
        st.subheader("ğŸ“Š ì˜¤ëŠ˜ì˜ ê³µí¬ ì§€ìˆ˜ (VIX)")

        # 1:2 ë¹„ìœ¨ë¡œ ì»¬ëŸ¼ ë¶„í•  (ì™¼ìª½: ìˆ˜ì¹˜, ì˜¤ë¥¸ìª½: ê·¸ë˜í”„)
        col1, col2 = st.columns([1, 2])

        with col1:
            st.metric(
                label="VIX ì§€ìˆ˜",
                value=f"{vix_val:.2f}",
                delta=f"{vix_delta:.2f}",
                delta_color="inverse",
            )
            # ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ
            if vix_val < 20:
                st.success("â˜€ï¸ ì ë“œê°€ì")
            elif vix_val < 30:
                st.warning("â˜ï¸ í•˜ê³ ì‹¶ìœ¼ë©´ í•´ë³´ì„¸ìš” ã…‹ã…‹")
            else:
                st.error(
                    "ğŸš¨ ì°¨íŠ¸ë³´ë©´ì„œ ë•€í˜ë¦¬ë©´ ìš´ë™ ë§ì´ ë ê±°ì•¼..ìŠ¤íŠ¸ë ˆìŠ¤ ë§ì´ ë°›ì„ê±°ì•¼.. "
                )

        with col2:
            # VIX ì¶”ì„¸ ê·¸ë˜í”„ (ìµœê·¼ 1ë‹¬)
            st.caption("ğŸ“‰ ìµœê·¼ 1ê°œì›” VIX ì¶”ì´")
            st.line_chart(vix_history, height=150, color="#FF0000")  # ë¶‰ì€ìƒ‰ ë¼ì¸ ì°¨íŠ¸

    ""
    "---"
    ""

    # â‘¡ ì›Œë“œí´ë¼ìš°ë“œ
    st.subheader("â˜ï¸ ì˜¤ëŠë¦ ê´€ì‹¬ ì¢…ëª©ë“¤")  # ì£¼ì˜ê¹Šê²Œ ë´ì•¼í•  íšŒì‚¬

    news_items = get_naver_news()

    if news_items:
        try:
            data_amount = st.slider("ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜", 1, 50, 10)
            wcChart(news_items)
        except Exception as e:
            st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}")

    ""
    "---"
    ""

    # â‘¢ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¦¬ìŠ¤íŠ¸
    st.subheader("ğŸ“° ì‹¤ì‹œê°„ ì£¼ìš” ë‰´ìŠ¤")

    if news_items:
        # ê¸°ì—…ë³„ë¡œ í•˜ë‚˜ë§Œ ë‚¨ê¸´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ìŒ
        unique_news = get_unique_companies(news_items)

        # ìƒìœ„ 15ê°œ ê¸°ì—… ì¶œë ¥
        for item in unique_news[:15]:
            with st.expander(f"ğŸ“Œ {item['title']}"):
                st.write(item["description"])
                st.markdown(f"[ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({item['link']})")
    else:
        st.write("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
